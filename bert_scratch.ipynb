{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_attention_heads):\n",
    "        super().__init__()\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.attention_head_size = int(hidden_size / num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(hidden_size, self.all_head_size)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None):\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "\n",
    "        query_layer = mixed_query_layer.view(\n",
    "            mixed_query_layer.size(0), -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
    "        key_layer = mixed_key_layer.view(\n",
    "            mixed_key_layer.size(0), -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
    "        value_layer = mixed_value_layer.view(\n",
    "            mixed_value_layer.size(0), -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
    "\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.unsqueeze(1).unsqueeze(3)\n",
    "            attention_mask = attention_mask.expand(-1, self.num_attention_heads, -1, -1)\n",
    "            attention_mask = attention_mask.to(dtype=attention_scores.dtype)  # Convert dtype to match\n",
    "            attention_scores += (attention_mask * -10000.0)\n",
    "\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "        \n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.transpose(1, 2).contiguous()\n",
    "        context_layer = context_layer.view(context_layer.size(0), -1, self.all_head_size)\n",
    "        return context_layer\n",
    "\n",
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "\n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_attention_heads):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(hidden_size, num_attention_heads)\n",
    "        self.output = BertSelfOutput(hidden_size)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None):\n",
    "        self_outputs = self.self(hidden_states, attention_mask)\n",
    "        attention_output = self.output(self_outputs, hidden_states)\n",
    "        return attention_output\n",
    "\n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, hidden_size, intermediate_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, intermediate_size)\n",
    "        self.intermediate_act_fn = nn.GELU()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, intermediate_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(intermediate_size, hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_attention_heads, intermediate_size):\n",
    "        super().__init__()\n",
    "        self.attention = BertAttention(hidden_size, num_attention_heads)\n",
    "        self.intermediate = BertIntermediate(hidden_size, intermediate_size)\n",
    "        self.output = BertOutput(intermediate_size, hidden_size)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None):\n",
    "        attention_output = self.attention(hidden_states, attention_mask)\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, num_attention_heads, intermediate_size, num_hidden_layers):\n",
    "        super().__init__()\n",
    "        self.layer = nn.ModuleList([BertLayer(hidden_size, num_attention_heads, intermediate_size) for _ in range(num_hidden_layers)])\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None):\n",
    "        for layer_module in self.layer:\n",
    "            hidden_states = layer_module(hidden_states, attention_mask)\n",
    "        return hidden_states\n",
    "\n",
    "class BertEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, max_position_embeddings):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, hidden_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(max_position_embeddings, hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(2, hidden_size)\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None):\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "        words_embeddings = self.word_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "class BertModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_attention_heads, intermediate_size, num_hidden_layers, max_position_embeddings):\n",
    "        super().__init__()\n",
    "        self.embeddings = BertEmbeddings(vocab_size, hidden_size, max_position_embeddings)\n",
    "        self.encoder = BertEncoder(hidden_size, num_attention_heads, intermediate_size, num_hidden_layers)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        embeddings = self.embeddings(input_ids, token_type_ids)\n",
    "        encoder_outputs = self.encoder(embeddings, attention_mask)\n",
    "        return encoder_outputs\n",
    "\n",
    "class BertForTokenClassification(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_attention_heads, intermediate_size, num_hidden_layers, max_position_embeddings, num_labels):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bert = BertModel(vocab_size, hidden_size, num_attention_heads, intermediate_size, num_hidden_layers, max_position_embeddings)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        sequence_output = self.dropout(outputs)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        if labels is None:\n",
    "            return logits\n",
    "        \n",
    "        active_loss = labels.view(-1) != -100\n",
    "        active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
    "        active_labels = labels.view(-1)[active_loss]\n",
    "        loss = self.loss_fn(active_logits, active_labels)\n",
    "\n",
    "        return {'logits':logits, 'loss':loss}\n",
    "    def update_num_labels(self, num_labels):\n",
    "        self.num_labels = num_labels\n",
    "        self.classifier = nn.Linear(self.hidden_size, num_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(self, vocab_file, config_file, special_tokens_file):\n",
    "        with open(vocab_file, 'r', encoding='utf-8') as file:\n",
    "            self.vocab = {line.strip(): idx for idx, line in enumerate(file.readlines())}\n",
    "        self.id_to_token = {idx: token for token, idx in self.vocab.items()}\n",
    "        \n",
    "        with open(config_file, 'r', encoding='utf-8') as file:\n",
    "            self.config = json.load(file)\n",
    "        \n",
    "        with open(special_tokens_file, 'r', encoding='utf-8') as file:\n",
    "            self.special_tokens = json.load(file)\n",
    "        self.current_word_indices = []\n",
    "        self.pad_token_id = self.vocab[self.special_tokens['pad_token']]\n",
    "    def tokenize(self, text):\n",
    "        tokens = []\n",
    "        self.current_word_indices = []\n",
    "        for word_index, word in enumerate(text):  # Split on spaces by default\n",
    "            sub_tokens = self.word_piece_tokenize(word)\n",
    "            tokens.extend(sub_tokens)\n",
    "            self.current_word_indices.extend([word_index] * len(sub_tokens))\n",
    "        return tokens\n",
    "\n",
    "    def word_piece_tokenize(self, word):\n",
    "        sub_tokens = []\n",
    "        start = 0\n",
    "        while start < len(word):\n",
    "            matched = False\n",
    "            for length in range(len(word), start, -1):\n",
    "                subword = ('' if start == 0 else '##') + word[start:length]\n",
    "                if subword in self.vocab:\n",
    "                    sub_tokens.append(subword)\n",
    "                    start = length\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                sub_tokens.append('##' + word[start] if start > 0 else self.special_tokens['unk_token'])\n",
    "                start += 1\n",
    "        return sub_tokens\n",
    "\n",
    "    def word_ids(self):\n",
    "        return self.current_word_indices\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return [self.vocab.get(token, self.vocab.get(self.special_tokens['unk_token'])) for token in tokens]\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        return [self.id_to_token.get(id, self.special_tokens['unk_token']) for id in ids]\n",
    "\n",
    "    def encode(self, text, text_pair=None, max_length=None, truncation=False, padding='max_length', is_split_into_words=False):\n",
    "        if is_split_into_words:\n",
    "            text = [i.lower() for i in text]  # Splits the text into words if not already split\n",
    "        tokens = ['[CLS]'] + self.tokenize(text) + ['[SEP]']\n",
    "        token_type_ids = [0] * len(tokens)\n",
    "        self.current_word_indices = [None] + self.current_word_indices + [None]\n",
    "\n",
    "        if text_pair:\n",
    "            pair_tokens = self.tokenize(text_pair)\n",
    "            tokens += pair_tokens + ['[SEP]']\n",
    "            token_type_ids += [1] * (len(pair_tokens) + 1)\n",
    "            self.current_word_indices += [None] * (len(pair_tokens) + 1)  \n",
    "\n",
    "        input_ids = self.convert_tokens_to_ids(tokens)\n",
    "        \n",
    "        if truncation and max_length:\n",
    "            input_ids = input_ids[:max_length]\n",
    "            token_type_ids = token_type_ids[:max_length]\n",
    "            self.current_word_indices = self.current_word_indices[:max_length]\n",
    "        \n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        \n",
    "        if padding and max_length:\n",
    "            padding_length = max_length - len(input_ids)\n",
    "            input_ids += [self.vocab.get(self.special_tokens['pad_token'])] * padding_length\n",
    "            token_type_ids += [0] * padding_length\n",
    "            attention_mask += [0] * padding_length\n",
    "            self.current_word_indices += [None] * padding_length \n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"token_type_ids\": token_type_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"word_ids\": self.current_word_indices  \n",
    "        }\n",
    "    \n",
    "    def __call__(self, text, text_pair=None, max_length=None, truncation=False, padding='max_length', is_split_into_words=False):\n",
    "        return self.encode(text, text_pair, max_length, truncation, padding, is_split_into_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CustomTokenizer('./tokenizer/vocab.txt', './tokenizer/tokenizer_config.json', './tokenizer/special_tokens_map.json')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 28996\n",
    "hidden_size = 768\n",
    "num_attention_heads = 12\n",
    "intermediate_size = 3072\n",
    "num_hidden_layers = 12\n",
    "max_position_embeddings = 512\n",
    "num_labels = 7\n",
    "\n",
    "model = BertForTokenClassification(vocab_size, hidden_size, num_attention_heads, intermediate_size, num_hidden_layers, max_position_embeddings, num_labels)\n",
    "\n",
    "model_path = '../va.pth'  \n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')), strict=False)\n",
    "model.to(device)\n",
    "\n",
    "model.update_num_labels(43)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in model.classifier.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "{'O': 0, 'B-DATE': 1, 'B-PATIENT': 2, 'I-PATIENT': 3, 'B-MEDICALRECORD': 4, 'B-DOCTOR': 5, 'I-DOCTOR': 6, 'B-AGE': 7, 'B-HOSPITAL': 8, 'I-HOSPITAL': 9, 'B-PHONE': 10, 'B-FAX': 11, 'B-PROFESSION': 12, 'B-COUNTRY': 13, 'B-IDNUM': 14, 'B-USERNAME': 15, 'B-STREET': 16, 'I-STREET': 17, 'B-CITY': 18, 'B-STATE': 19, 'B-ZIP': 20, 'I-DATE': 21, 'I-PHONE': 22, 'I-MEDICALRECORD': 23, 'I-CITY': 24, 'B-ORGANIZATION': 25, 'I-PROFESSION': 26, 'I-ORGANIZATION': 27, 'I-IDNUM': 28, 'B-HEALTHPLAN': 29, 'I-HEALTHPLAN': 30, 'B-DEVICE': 31, 'B-BIOID': 32, 'B-EMAIL': 33, 'I-COUNTRY': 34, 'B-LOCATION-OTHER': 35, 'I-LOCATION-OTHER': 36, 'I-AGE': 37, 'I-FAX': 38, 'I-STATE': 39, 'B-URL': 40, 'I-URL': 41, 'I-DEVICE': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2872 [00:00<?, ?it/s]C:\\Users\\jstam\\AppData\\Local\\Temp\\ipykernel_19308\\317212729.py:369: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  [torch.tensor(seq) for seq in input_ids],\n",
      "C:\\Users\\jstam\\AppData\\Local\\Temp\\ipykernel_19308\\317212729.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  [torch.tensor(lab) for lab in labels],\n",
      "Training: 100%|██████████| 2872/2872 [08:41<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Average training loss: 0.08158660268870783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 309/309 [00:17<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\tprecision\trecall\tf1\t\n",
      "AGE\t0.9850\t0.9632\t0.9740\n",
      "CITY\t0.7521\t0.9263\t0.8302\n",
      "COUNTRY\t0.0000\t0.0000\t0.0000\n",
      "DATE\t0.9900\t0.9845\t0.9872\n",
      "DOCTOR\t0.9343\t0.9373\t0.9358\n",
      "HOSPITAL\t0.8904\t0.8149\t0.8510\n",
      "IDNUM\t0.9903\t0.9111\t0.9491\n",
      "MEDICALRECORD\t0.9400\t0.9975\t0.9679\n",
      "ORGANIZATION\t0.7778\t0.5000\t0.6087\n",
      "PATIENT\t0.8886\t0.8123\t0.8487\n",
      "PHONE\t0.8590\t0.8121\t0.8349\n",
      "PROFESSION\t0.6296\t0.6800\t0.6538\n",
      "STATE\t0.9773\t0.8113\t0.8866\n",
      "STREET\t0.8372\t0.8000\t0.8182\n",
      "USERNAME\t1.0000\t1.0000\t1.0000\n",
      "ZIP\t0.9892\t1.0000\t0.9946\n",
      "\n",
      "Overall micro-average precision: 0.9561\n",
      "Overall micro-average recall:    0.9424\n",
      "Overall micro-average f1:       0.9492\n",
      "\n",
      "label\tprecision\trecall\tf1\t\n",
      "AGE\t0.9850\t0.9632\t0.9740\n",
      "CITY\t0.7521\t0.9263\t0.8302\n",
      "COUNTRY\t0.0000\t0.0000\t0.0000\n",
      "DATE\t0.9900\t0.9845\t0.9872\n",
      "DOCTOR\t0.9343\t0.9373\t0.9358\n",
      "HOSPITAL\t0.8904\t0.8149\t0.8510\n",
      "IDNUM\t0.9903\t0.9111\t0.9491\n",
      "MEDICALRECORD\t0.9400\t0.9975\t0.9679\n",
      "ORGANIZATION\t0.7778\t0.5000\t0.6087\n",
      "PATIENT\t0.8886\t0.8123\t0.8487\n",
      "PHONE\t0.8590\t0.8121\t0.8349\n",
      "PROFESSION\t0.6296\t0.6800\t0.6538\n",
      "STATE\t0.9773\t0.8113\t0.8866\n",
      "STREET\t0.8372\t0.8000\t0.8182\n",
      "USERNAME\t1.0000\t1.0000\t1.0000\n",
      "ZIP\t0.9892\t1.0000\t0.9946\n",
      "\n",
      "Overall micro-average precision: 0.9561\n",
      "Overall micro-average recall:    0.9424\n",
      "Overall micro-average f1:       0.9492\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2037/2037 [01:52<00:00, 18.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\tprecision\trecall\tf1\t\n",
      "AGE\t0.9639\t0.9780\t0.9709\n",
      "CITY\t0.4368\t0.7379\t0.5487\n",
      "COUNTRY\t0.0000\t0.0000\t0.0000\n",
      "DATE\t0.9884\t0.9912\t0.9898\n",
      "DEVICE\t0.0000\t0.0000\t0.0000\n",
      "DOCTOR\t0.9280\t0.9288\t0.9284\n",
      "EMAIL\t0.0000\t0.0000\t0.0000\n",
      "FAX\t0.0000\t0.0000\t0.0000\n",
      "HOSPITAL\t0.8132\t0.8628\t0.8373\n",
      "IDNUM\t0.9242\t0.8824\t0.9028\n",
      "LOCATION-OTHER\t0.0000\t0.0000\t0.0000\n",
      "MEDICALRECORD\t0.8965\t0.9841\t0.9383\n",
      "ORGANIZATION\t0.4737\t0.2885\t0.3586\n",
      "PATIENT\t0.8715\t0.8644\t0.8679\n",
      "PHONE\t0.7407\t0.7632\t0.7517\n",
      "PROFESSION\t0.5290\t0.6109\t0.5670\n",
      "STATE\t0.7660\t0.6585\t0.7082\n",
      "STREET\t0.8877\t0.8737\t0.8806\n",
      "USERNAME\t0.9431\t0.9559\t0.9495\n",
      "ZIP\t0.9030\t0.9270\t0.9148\n",
      "\n",
      "Overall micro-average precision: 0.9299\n",
      "Overall micro-average recall:    0.9377\n",
      "Overall micro-average f1:       0.9338\n",
      "\n",
      "label\tprecision\trecall\tf1\t\n",
      "AGE\t0.9639\t0.9780\t0.9709\n",
      "CITY\t0.4368\t0.7379\t0.5487\n",
      "COUNTRY\t0.0000\t0.0000\t0.0000\n",
      "DATE\t0.9884\t0.9912\t0.9898\n",
      "DEVICE\t0.0000\t0.0000\t0.0000\n",
      "DOCTOR\t0.9280\t0.9288\t0.9284\n",
      "EMAIL\t0.0000\t0.0000\t0.0000\n",
      "FAX\t0.0000\t0.0000\t0.0000\n",
      "HOSPITAL\t0.8132\t0.8628\t0.8373\n",
      "IDNUM\t0.9242\t0.8824\t0.9028\n",
      "LOCATION-OTHER\t0.0000\t0.0000\t0.0000\n",
      "MEDICALRECORD\t0.8965\t0.9841\t0.9383\n",
      "ORGANIZATION\t0.4737\t0.2885\t0.3586\n",
      "PATIENT\t0.8715\t0.8644\t0.8679\n",
      "PHONE\t0.7407\t0.7632\t0.7517\n",
      "PROFESSION\t0.5290\t0.6109\t0.5670\n",
      "STATE\t0.7660\t0.6585\t0.7082\n",
      "STREET\t0.8877\t0.8737\t0.8806\n",
      "USERNAME\t0.9431\t0.9559\t0.9495\n",
      "ZIP\t0.9030\t0.9270\t0.9148\n",
      "\n",
      "Overall micro-average precision: 0.9299\n",
      "Overall micro-average recall:    0.9377\n",
      "Overall micro-average f1:       0.9338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\"\"\"\n",
    "Data can be found at Harvard:\n",
    "training, val, test tsv file data looks like this:\n",
    "\n",
    "Mr. O\n",
    "Steiner B-PATIENT\n",
    "is O\n",
    "scheduled O\n",
    "today. O\n",
    "Patient O\n",
    "has O\n",
    "not O\n",
    "been O\n",
    "seen O\n",
    "since O\n",
    "November B-DATE\n",
    ". O\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def write_predictions_to_file(model, data_loader, device, idx2tag, output_file):\n",
    "    model.eval()\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(data_loader, desc=\"Writing predictions\"):\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                logits = outputs.logits\n",
    "                input_ids = batch['input_ids']\n",
    "                attention_mask = batch['attention_mask']\n",
    "                \n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                input_ids = input_ids.detach().cpu().numpy()\n",
    "                attention_mask = attention_mask.detach().cpu().numpy()\n",
    "                \n",
    "                for seq_idx in range(len(input_ids)):\n",
    "                    tokens = tokenizer.convert_ids_to_tokens(input_ids[seq_idx])\n",
    "                    pred_labels = np.argmax(logits[seq_idx], axis=1)\n",
    "                    mask = attention_mask[seq_idx]\n",
    "                    \n",
    "                    current_word = \"\"\n",
    "                    current_word_label = None\n",
    "                    \n",
    "                    for token_idx in range(len(tokens)):\n",
    "                        if not mask[token_idx]:\n",
    "                            break\n",
    "                        token = tokens[token_idx]\n",
    "                        pred_label = idx2tag[pred_labels[token_idx]]\n",
    "                        \n",
    "                        if token in [tokenizer.pad_token, tokenizer.cls_token, tokenizer.sep_token]:\n",
    "                            continue\n",
    "                            \n",
    "                        # Handle subwords while preserving punctuation\n",
    "                        if token.startswith(\"##\"):\n",
    "                            current_word += token[2:]\n",
    "                        else:\n",
    "                            if current_word:\n",
    "                                f.write(f\"{current_word} {current_word_label}\\n\")\n",
    "                            current_word = token\n",
    "                            current_word_label = pred_label\n",
    "                    \n",
    "                    if current_word:\n",
    "                        f.write(f\"{current_word} {current_word_label}\\n\")\n",
    "                    \n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "\n",
    "def get_entities_from_iob(seq):\n",
    "\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    current_start = None\n",
    "    current_label = None\n",
    "    \n",
    "    for i, tag in enumerate(seq):\n",
    "        if tag == \"O\" or tag.startswith(\"B-\"):\n",
    "            # If we were tracking an entity, close it out\n",
    "            if current_entity is not None:\n",
    "                entities.append((current_entity, current_start, i - 1))\n",
    "                current_entity = None\n",
    "                current_start = None\n",
    "            # Start of a new entity?\n",
    "            if tag.startswith(\"B-\"):\n",
    "                current_entity = tag[2:]  # remove the \"B-\"\n",
    "                current_start = i\n",
    "                \n",
    "        elif tag.startswith(\"I-\"):\n",
    "            # Continue the current entity if it matches the same type\n",
    "            if current_entity is None:\n",
    "                # This handles a corner case: \"I-*\" appears without a preceding \"B-*\"\n",
    "                current_entity = tag[2:]\n",
    "                current_start = i\n",
    "            else:\n",
    "                # Check if we switched to a different entity type incorrectly\n",
    "                current_label = tag[2:]\n",
    "                if current_label != current_entity:\n",
    "                    # Close out the previous entity and start a new one\n",
    "                    entities.append((current_entity, current_start, i - 1))\n",
    "                    current_entity = current_label\n",
    "                    current_start = i\n",
    "        else:\n",
    "            # Shouldn't happen with standard IOB, but just in case\n",
    "            pass\n",
    "\n",
    "    # If we ended in the middle of an entity\n",
    "    if current_entity is not None:\n",
    "        entities.append((current_entity, current_start, len(seq) - 1))\n",
    "    \n",
    "    return entities\n",
    "\n",
    "def compute_chunk_metrics(true_list, pred_list):\n",
    "\n",
    "    assert len(true_list) == len(pred_list), \"Number of examples differs!\"\n",
    "    \n",
    "    true_entities_all = 0\n",
    "    pred_entities_all = 0\n",
    "    match_entities_all = 0\n",
    "    \n",
    "    # For label-wise stats\n",
    "    label_wise_stats = defaultdict(lambda: {\"TP\": 0, \"FP\": 0, \"FN\": 0})\n",
    "    \n",
    "    for true_seq, pred_seq in zip(true_list, pred_list):\n",
    "        true_entities = get_entities_from_iob(true_seq)\n",
    "        pred_entities = get_entities_from_iob(pred_seq)\n",
    "        \n",
    "        # Convert to sets for direct matching\n",
    "        # We'll store them as (type, start, end)\n",
    "        true_set = set(true_entities)\n",
    "        pred_set = set(pred_entities)\n",
    "        \n",
    "        # For micro-averaging\n",
    "        true_entities_all += len(true_set)\n",
    "        pred_entities_all += len(pred_set)\n",
    "        \n",
    "        # Count matches\n",
    "        matches = true_set.intersection(pred_set)\n",
    "        match_entities_all += len(matches)\n",
    "        \n",
    "        # --- Label-wise stats ---\n",
    "        # We'll track each entity in sets by label\n",
    "        # A chunk is identified by the entity type.\n",
    "        \n",
    "        # Tally for each entity in \"true_set\"\n",
    "        for ent in true_set:\n",
    "            label = ent[0]\n",
    "            # If it's not matched, it counts as FN\n",
    "            if ent in matches:\n",
    "                label_wise_stats[label][\"TP\"] += 1\n",
    "            else:\n",
    "                label_wise_stats[label][\"FN\"] += 1\n",
    "        \n",
    "        # Tally for each entity in \"pred_set\"\n",
    "        for ent in pred_set:\n",
    "            label = ent[0]\n",
    "            # If it's not matched, it counts as FP\n",
    "            if ent not in matches:\n",
    "                label_wise_stats[label][\"FP\"] += 1\n",
    "\n",
    "    # Compute overall micro P/R/F\n",
    "    if pred_entities_all == 0:\n",
    "        precision = 0.0\n",
    "    else:\n",
    "        precision = match_entities_all / pred_entities_all\n",
    "    \n",
    "    if true_entities_all == 0:\n",
    "        recall = 0.0\n",
    "    else:\n",
    "        recall = match_entities_all / true_entities_all\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    # Build a simple label-wise classification report\n",
    "    classification_report_str = \"label\\tprecision\\trecall\\tf1\\t\\n\"\n",
    "    for label, stats in sorted(label_wise_stats.items()):\n",
    "        tp = stats[\"TP\"]\n",
    "        fp = stats[\"FP\"]\n",
    "        fn = stats[\"FN\"]\n",
    "        if (tp + fp) == 0:\n",
    "            precision_label = 0.0\n",
    "        else:\n",
    "            precision_label = tp / (tp + fp)\n",
    "        if (tp + fn) == 0:\n",
    "            recall_label = 0.0\n",
    "        else:\n",
    "            recall_label = tp / (tp + fn)\n",
    "        if precision_label + recall_label == 0:\n",
    "            f1_label = 0.0\n",
    "        else:\n",
    "            f1_label = 2 * precision_label * recall_label / (precision_label + recall_label)\n",
    "\n",
    "        classification_report_str += (\n",
    "            f\"{label}\\t\"\n",
    "            f\"{precision_label:.4f}\\t\"\n",
    "            f\"{recall_label:.4f}\\t\"\n",
    "            f\"{f1_label:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "    # Add overall micro-average\n",
    "    classification_report_str += (\n",
    "        \"\\nOverall micro-average precision: {:.4f}\\n\".format(precision)\n",
    "        + \"Overall micro-average recall:    {:.4f}\\n\".format(recall)\n",
    "        + \"Overall micro-average f1:       {:.4f}\\n\".format(f1)\n",
    "    )\n",
    "    \n",
    "    return classification_report_str, {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics(model, data_loader, device, idx2tag):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs[\"logits\"]\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            # Move tensors to CPU and convert to numpy\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                pred_tags = []\n",
    "                true_tags = []\n",
    "                for j in range(len(labels[i])):\n",
    "                    if labels[i][j] != -100:\n",
    "                        # predicted label\n",
    "                        pred_tag = idx2tag[np.argmax(logits[i][j])]\n",
    "                        # gold label\n",
    "                        true_tag = idx2tag[labels[i][j]]\n",
    "                        pred_tags.append(pred_tag)\n",
    "                        true_tags.append(true_tag)\n",
    "                predictions.append(pred_tags)\n",
    "                true_labels.append(true_tags)\n",
    "\n",
    "    # Generate chunk-based classification report\n",
    "    report, summary_dict = compute_chunk_metrics(true_labels, predictions)\n",
    "    print(report)\n",
    "    return report\n",
    "\n",
    "\n",
    "train_path = '../data/train.tsv'\n",
    "val_path = '../data/dev.tsv'\n",
    "test_path = '../data/test.tsv'\n",
    "\n",
    "def parse_tsv_to_sentences_with_tags(file_path):\n",
    "    sentences_data = []\n",
    "    current_words = []\n",
    "    current_tags = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:  # If the line is not empty\n",
    "                if \" \" in line:\n",
    "                    # Split only on the first space to preserve any spaces in the tag\n",
    "                    parts = line.split(\" \", 1)\n",
    "                    if len(parts) == 2:\n",
    "                        word, tag = parts\n",
    "                        # Don't modify the word - keep it exactly as is\n",
    "                        current_words.append(word)\n",
    "                        current_tags.append(tag)\n",
    "                    else:\n",
    "                        print(f\"Skipping malformed line: '{line}'\")\n",
    "            else:  # Empty line indicates end of a sentence\n",
    "                if current_words and current_tags:\n",
    "                    sentences_data.append((current_words, current_tags))\n",
    "                    current_words = []\n",
    "                    current_tags = []\n",
    "\n",
    "    # Don't forget to add the last sentence if not empty\n",
    "    if current_words and current_tags:\n",
    "        sentences_data.append((current_words, current_tags))\n",
    "\n",
    "    return pd.DataFrame(sentences_data, columns=['Sentence', 'Tag'])\n",
    "\n",
    "# Parse the data\n",
    "train_df = parse_tsv_to_sentences_with_tags(train_path)\n",
    "val_df = parse_tsv_to_sentences_with_tags(val_path)\n",
    "test_df = parse_tsv_to_sentences_with_tags(test_path)\n",
    "all_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "def process_data_for_training(train_df, val_df, test_df):\n",
    "    all_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "    words = Counter()\n",
    "    tags = Counter()\n",
    "    \n",
    "    for _, row in all_df.iterrows():\n",
    "        words.update(row['Sentence'])\n",
    "        tags.update(row['Tag'])\n",
    "\n",
    "    word2idx = {word: i + 1 for i, (word, _) in enumerate(words.items())}\n",
    "    word2idx['<UNK>'] = 0\n",
    "    tag2idx = {tag: i for i, (tag, _) in enumerate(tags.items())}\n",
    "    idx2tag = {i: tag for tag, i in tag2idx.items()}\n",
    "    \n",
    "    return word2idx, tag2idx, idx2tag\n",
    "\n",
    "words = Counter()\n",
    "tags = Counter()\n",
    "for _, row in all_df.iterrows():\n",
    "    words.update(row['Sentence'])\n",
    "    tags.update(row['Tag'])\n",
    "\n",
    "word2idx = {word: i + 1 for i, (word, _) in enumerate(words.items())}\n",
    "word2idx['<UNK>'] = 0\n",
    "tag2idx = {tag: i for i, (tag, _) in enumerate(tags.items())}\n",
    "idx2tag = {i: tag for tag, i in tag2idx.items()}\n",
    "label_list = [name for name, idx in tag2idx.items() ]\n",
    "print(len(tag2idx))\n",
    "print(tag2idx)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "\n",
    "    # Padding\n",
    "    input_ids_padded = pad_sequence(\n",
    "        [torch.tensor(seq) for seq in input_ids], \n",
    "        batch_first=True, \n",
    "        padding_value=tokenizer.pad_token_id\n",
    "    )\n",
    "    labels_padded = pad_sequence(\n",
    "        [torch.tensor(lab) for lab in labels], \n",
    "        batch_first=True, \n",
    "        padding_value=-100\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids_padded,\n",
    "        'attention_mask': input_ids_padded != tokenizer.pad_token_id,\n",
    "        'labels': labels_padded\n",
    "    }\n",
    "\n",
    "class CustomDataset:\n",
    "    def __init__(self, dataframe, tokenizer, tag2idx, max_len=150):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tag2idx = tag2idx\n",
    "        self.max_len = max_len\n",
    "        self.label_all_tokens = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_row = self.data.iloc[idx]\n",
    "        sentence, tags = data_row['Sentence'], data_row['Tag']\n",
    "        \n",
    "        # Use is_split_into_words=True since our input is already tokenized\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "        sentence,\n",
    "        is_split_into_words=True,\n",
    "        max_length=self.max_len,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "        )\n",
    "\n",
    "        # Build label_ids from 'word_ids', but we won't return 'word_ids' to avoid None\n",
    "        labels = [self.tag2idx.get(tag, -100) for tag in tags]\n",
    "        word_ids = tokenized_inputs[\"word_ids\"]  # has None for [CLS], [SEP], padding\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(labels[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        tokenized_inputs['labels'] = label_ids\n",
    "\n",
    "        # Remove the 'word_ids' field:\n",
    "        del tokenized_inputs['word_ids']\n",
    "\n",
    "        return {key: torch.tensor(val) for key, val in tokenized_inputs.items()}\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_df, tokenizer, tag2idx)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "test_dataset = CustomDataset(test_df, tokenizer, tag2idx)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "val_dataset = CustomDataset(val_df, tokenizer, tag2idx)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 1\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01) \n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=1,\n",
    "    num_training_steps=len(train_loader) * num_epochs\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs['loss']\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), max_norm=0.7)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Average training loss: {total_loss / len(train_loader)}\")\n",
    "    \n",
    "    # Evaluate on the validation set (we only write predictions to file here)\n",
    "    #_ = write_predictions_to_file(model, val_loader, device, idx2tag, 'mytext.txt')\n",
    "    val_report = compute_metrics(model, val_loader, device, idx2tag)\n",
    "    print(val_report)\n",
    "\n",
    "# Final evaluation on the test set (chunk-based metrics)\n",
    "test_report = compute_metrics(model, test_loader, device, idx2tag)\n",
    "print(test_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = set()\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    for tags in df[\"Tag\"]:\n",
    "        all_tags.update(tags)\n",
    "all_tags = sorted(list(all_tags))\n",
    "\n",
    "# Create dictionaries for label -> ID and ID -> label\n",
    "label2id = {tag: i for i, tag in enumerate(all_tags)}\n",
    "id2label = {i: tag for tag, i in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "from bert_attack_utils2 import(\n",
    "\n",
    "    get_word_embeddings,\n",
    "    get_char_table,\n",
    "    greedy_5char_attack,\n",
    "    genetic_5char_attack,\n",
    "    compute_average_metrics,\n",
    "    evaluate_attacks,\n",
    "    similarity,\n",
    "    PGD5CharAttacker\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.5000\n",
      "  recall: 0.3333\n",
      "  f1: 0.4000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.5000\n",
      "  recall: 1.0000\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.5000\n",
      "  recall: 1.0000\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.5000\n",
      "  recall: 1.0000\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.3333\n",
      "  recall: 0.3333\n",
      "  f1: 0.3333\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.3333\n",
      "  recall: 0.3333\n",
      "  f1: 0.3333\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 0.6667\n",
      "  f1: 0.8000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 0.5000\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.3333\n",
      "  recall: 0.5000\n",
      "  f1: 0.4000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.2500\n",
      "  recall: 0.3333\n",
      "  f1: 0.2857\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.6667\n",
      "  recall: 0.5000\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.6667\n",
      "  recall: 0.5000\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.6667\n",
      "  recall: 0.5000\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 0.2500\n",
      "  f1: 0.4000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.6667\n",
      "  recall: 1.0000\n",
      "  f1: 0.8000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 0.8571\n",
      "  f1: 0.9231\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.3333\n",
      "  recall: 0.1429\n",
      "  f1: 0.2000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.2500\n",
      "  recall: 0.5000\n",
      "  f1: 0.3333\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.2500\n",
      "  recall: 0.3333\n",
      "  f1: 0.2857\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.3333\n",
      "  recall: 0.5000\n",
      "  f1: 0.4000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.6667\n",
      "  recall: 1.0000\n",
      "  f1: 0.8000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.5000\n",
      "  recall: 0.3333\n",
      "  f1: 0.4000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.5000\n",
      "  recall: 0.3333\n",
      "  f1: 0.4000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.5000\n",
      "  recall: 1.0000\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.5000\n",
      "  recall: 1.0000\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.5000\n",
      "  recall: 1.0000\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.5000\n",
      "  recall: 0.3333\n",
      "  f1: 0.4000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.3333\n",
      "  recall: 0.3333\n",
      "  f1: 0.3333\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.3333\n",
      "  recall: 0.3333\n",
      "  f1: 0.3333\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 0.6667\n",
      "  f1: 0.8000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.5000\n",
      "  recall: 0.5000\n",
      "  f1: 0.5000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.3333\n",
      "  recall: 0.5000\n",
      "  f1: 0.4000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 0.5000\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.6667\n",
      "  recall: 0.6667\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.6667\n",
      "  recall: 0.5000\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.6667\n",
      "  recall: 0.5000\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.6667\n",
      "  recall: 0.5000\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.2857\n",
      "  recall: 0.5000\n",
      "  f1: 0.3636\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 0.8571\n",
      "  f1: 0.9231\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.6667\n",
      "  recall: 0.6667\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.3333\n",
      "  recall: 0.5000\n",
      "  f1: 0.4000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 0.6667\n",
      "  f1: 0.8000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.6667\n",
      "  recall: 0.6667\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.5000\n",
      "  recall: 1.0000\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.5000\n",
      "  recall: 1.0000\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.5000\n",
      "  recall: 0.3333\n",
      "  f1: 0.4000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.3333\n",
      "  recall: 0.3333\n",
      "  f1: 0.3333\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.3333\n",
      "  recall: 0.3333\n",
      "  f1: 0.3333\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 0.6667\n",
      "  f1: 0.8000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.3333\n",
      "  recall: 0.3333\n",
      "  f1: 0.3333\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.3333\n",
      "  recall: 1.0000\n",
      "  f1: 0.5000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.6667\n",
      "  recall: 0.5000\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.6667\n",
      "  recall: 0.5000\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.6667\n",
      "  recall: 0.5000\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 0.8571\n",
      "  f1: 0.9231\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 0.7143\n",
      "  f1: 0.8333\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.3333\n",
      "  recall: 0.1429\n",
      "  f1: 0.2000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.6667\n",
      "  recall: 0.6667\n",
      "  f1: 0.6667\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  f1: 0.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.5000\n",
      "  recall: 0.6667\n",
      "  f1: 0.5714\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "ORIGINAL\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "-----------------------\n",
      "GREEDY\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "GENETIC\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "PGD\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "-----------------------\n",
      "HOMOGLYPH\n",
      "  precision: 0.5000\n",
      "  recall: 0.5000\n",
      "  f1: 0.5000\n",
      "-----------------------\n",
      "{'greedy': {'mean': 0.9955687344074249, 'std': 0.0012480511113202055}, 'genetic': {'mean': 0.9972728381554286, 'std': 0.0008738731241033512}, 'pgd': {'mean': 0.9943075031042099, 'std': 0.0013483562916861203}, 'homoglyph': {'mean': 0.9953720877567928, 'std': 0.00223381350571681}}\n"
     ]
    }
   ],
   "source": [
    "def get_cyrillic_char_table():\n",
    "    return {\n",
    "        'A': 'А',  # Cyrillic capital A\n",
    "        'a': 'а',  # Cyrillic lowercase a\n",
    "        'B': 'В',  # Cyrillic capital Ve\n",
    "        'E': 'Е',  # Cyrillic capital Ye\n",
    "        'e': 'е',  # Cyrillic small Ye\n",
    "        'I': 'І',  # Cyrillic capital Byelorussian-Ukrainian I\n",
    "        'i': 'і',  # Cyrillic small Byelorussian-Ukrainian i\n",
    "        'K': 'К',  # Cyrillic capital Ka\n",
    "        'k': 'к',  # Cyrillic small Ka\n",
    "        'M': 'М',  # Cyrillic capital Em\n",
    "        'm': 'м',  # Cyrillic small Em\n",
    "        'H': 'Н',  # Cyrillic capital En\n",
    "        'O': 'О',  # Cyrillic capital O\n",
    "        'o': 'о',  # Cyrillic small o\n",
    "        'P': 'Р',  # Cyrillic capital Er\n",
    "        'p': 'р',  # Cyrillic small er\n",
    "        'C': 'С',  # Cyrillic capital Es\n",
    "        'c': 'с',  # Cyrillic small es\n",
    "        'T': 'Т',  # Cyrillic capital Te\n",
    "        't': 'т',  # Cyrillic small te\n",
    "        'y': 'у',  # Cyrillic small u\n",
    "        'X': 'Х',  # Cyrillic capital Ha\n",
    "        'x': 'х',  # Cyrillic small ha\n",
    "    }\n",
    "\n",
    "import random\n",
    "\n",
    "def homoglyph_attack_5chars(text, char_table, model, tokenizer, num_replacements=5):\n",
    "    text_chars = list(text)\n",
    "    \n",
    "    replaceable_indices = [\n",
    "        i for i, ch in enumerate(text_chars) if ch in char_table\n",
    "    ]\n",
    "    \n",
    "\n",
    "    random.shuffle(replaceable_indices)\n",
    "    indices_to_replace = replaceable_indices[:num_replacements]\n",
    "    \n",
    "    # Perform the replacements\n",
    "    for idx in indices_to_replace:\n",
    "        ascii_char = text_chars[idx]\n",
    "        text_chars[idx] = char_table[ascii_char]\n",
    "    \n",
    "    attacked_text = \"\".join(text_chars)\n",
    "    orig_emb = get_word_embeddings(model,tokenizer,text)\n",
    "    new_emb = get_word_embeddings(model, tokenizer, attacked_text)\n",
    "    sim_val = similarity(orig_emb, new_emb)\n",
    "    return attacked_text, sim_val\n",
    "\n",
    "char_table = get_char_table()\n",
    "cyrillic_char_table = get_cyrillic_char_table()\n",
    "\n",
    "original_texts = [\n",
    "\"Dr. Sanders asked Maria to schedule her surgery on March 12, 2025.\",\n",
    "\"The clinic informed Michael at 555-987-6543 about his blood test results.\",\n",
    "\"Nurse Alexis emailed the patient’s treatment plan to james.clark@hospital.org.\",\n",
    "\"Taylor was advised to visit Room 204 at 9:00 AM on 06/15/2024 for a follow-up.\",\n",
    "\"Dr. Liu needs to review Lucas’s MRI scan results on April 8th.\",\n",
    "\"Ms. Jenkins left a voicemail at 555-222-3333 confirming her next appointment.\",\n",
    "\"The hospital asked Christopher to update his insurance details by 07/01/2025.\",\n",
    "\"At 2:00 PM on January 4, 2025, Dr. Patel met with Ms. Peterson to discuss lab findings.\",\n",
    "\"Please instruct Amanda to email her medical history to patient.records@healthclinic.com.\",\n",
    "\"Dr. Gomez recommended that Peter come back for tests every week until July 30, 2025.\",\n",
    "\"Caroline’s patient ID is 987654, and she must present it during the check-in process.\",\n",
    "\"The cardiologist requested that Mr. Delaney return on 10/31/2025 for a stress test.\",\n",
    "\"The nurse reminded Joshua to call 555-111-2222 if he experiences any chest pain.\",\n",
    "\"Mrs. Ramirez has an appointment scheduled at 3:15 PM on February 20th with Dr. Vaughn.\",\n",
    "\"Please send Tyler’s updated x-ray scans to t.henderson@medcenter.edu.\",\n",
    "\"Ms. Nguyen’s biopsy results will be discussed during her phone consultation at 555-654-3210.\",\n",
    "\"Dr. Cole instructed Harriet to rest for two weeks following her surgery on 08/25/2025.\",\n",
    "\"The dental office informed Mr. James that his cleaning was moved to May 6th at 10:00 AM.\",\n",
    "\"Lisa’s recovery plan was emailed to her personal address, lisa.phelps@example.com, by Dr. Fisher.\",\n",
    "\"Nurse Torres asked Jonathan to arrive at 8:30 AM on 09/09/2025 for routine bloodwork.\"\n",
    "\n",
    "]\n",
    "total_results = []\n",
    "similarity_results = defaultdict(list)\n",
    "for num in range(3):\n",
    "    for original_text in original_texts:\n",
    "        attacked_text_greedy, sim_greedy = greedy_5char_attack(\n",
    "            original_text,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            char_table\n",
    "        )\n",
    "\n",
    "        attacked_text_genetic, sim_genetic = genetic_5char_attack(\n",
    "            original_text,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            char_table,\n",
    "            pop_size=10,\n",
    "            generations=5,\n",
    "            mutation_rate=0.1\n",
    "        )\n",
    "\n",
    "        pgd_attacker = PGD5CharAttacker(model, tokenizer, char_table, max_iter=20)\n",
    "        attacked_text_pgd, sim_pgd = pgd_attacker.attack(original_text)    \n",
    "\n",
    "\n",
    "        attacked_text_homog, sim_homog = homoglyph_attack_5chars(\n",
    "            original_text, \n",
    "            cyrillic_char_table, \n",
    "            model, \n",
    "            tokenizer, \n",
    "            num_replacements=5)\n",
    "\n",
    "\n",
    "        attack_texts = {\n",
    "            \"greedy\": attacked_text_greedy,\n",
    "            \"genetic\": attacked_text_genetic,\n",
    "            \"pgd\": attacked_text_pgd,\n",
    "            \"homoglyph\": attacked_text_homog\n",
    "        }\n",
    "\n",
    "        eval_results = evaluate_attacks(\n",
    "            original_text=original_text,\n",
    "            attack_texts=attack_texts,\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            idx2tag=idx2tag\n",
    "        )\n",
    "        total_results.append((original_text, eval_results))\n",
    "\n",
    "        for attack_name, metric_dict in eval_results.items():\n",
    "            print(f\"{attack_name.upper()}\")\n",
    "            for k, v in metric_dict.items():\n",
    "                print(f\"  {k}: {v:.4f}\")\n",
    "            print(\"-----------------------\")\n",
    "        similarity_results['greedy'].append(sim_greedy)\n",
    "        similarity_results['genetic'].append(sim_genetic)\n",
    "        similarity_results['pgd'].append(sim_pgd)\n",
    "        similarity_results['homoglyph'].append(sim_homog)\n",
    "\n",
    "stats_dict = {}\n",
    "for method, scores in similarity_results.items():\n",
    "    scores_array = np.array(scores)\n",
    "    stats_dict[method] = {\n",
    "        'mean': float(np.mean(scores_array)),\n",
    "        'std': float(np.std(scores_array)),\n",
    "    }\n",
    "print(stats_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_metrics(total_results, attack_names=None):\n",
    "    \"\"\"\n",
    "    total_results is a list of (original_text, eval_results) pairs.\n",
    "    Each eval_results is what evaluate_attacks() returns.\n",
    "    \"\"\"\n",
    "    if attack_names is None:\n",
    "        attack_names = [\"original\", \"greedy\", \"genetic\", \"pgd\", \"homoglyph\"]\n",
    "\n",
    "    metric_sums = {\n",
    "        a: {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0,}\n",
    "        for a in attack_names\n",
    "    }\n",
    "    count = len(total_results)\n",
    "\n",
    "    for _, eval_res in total_results:\n",
    "        for attack_name in attack_names:\n",
    "            if attack_name not in eval_res:\n",
    "                continue\n",
    "            for m in [\"precision\", \"recall\", \"f1\"]:\n",
    "                metric_sums[attack_name][m] += eval_res[attack_name][m]\n",
    "\n",
    "    for attack_name in attack_names:\n",
    "        for m in [\"precision\", \"recall\", \"f1\", ]:\n",
    "            metric_sums[attack_name][m] /= max(1, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dr. Sanders asked Maria to schedule her surgery on March 12, 2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}}), ('The clinic informed Michael at 555-987-6543 about his blood test results.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4}}), ('Nurse Alexis emailed the patient’s treatment plan to james.clark@hospital.org.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}, 'genetic': {'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}, 'pgd': {'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Taylor was advised to visit Room 204 at 9:00 AM on 06/15/2024 for a follow-up.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}, 'genetic': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}, 'pgd': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Dr. Liu needs to review Lucas’s MRI scan results on April 8th.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333}, 'genetic': {'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333}, 'pgd': {'precision': 1.0, 'recall': 0.6666666666666666, 'f1': 0.8}, 'homoglyph': {'precision': 1.0, 'recall': 0.5, 'f1': 0.6666666666666666}}), ('Ms. Jenkins left a voicemail at 555-222-3333 confirming her next appointment.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}), ('The hospital asked Christopher to update his insurance details by 07/01/2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4}}), ('At 2:00 PM on January 4, 2025, Dr. Patel met with Ms. Peterson to discuss lab findings.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575}}), ('Please instruct Amanda to email her medical history to patient.records@healthclinic.com.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Dr. Gomez recommended that Peter come back for tests every week until July 30, 2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715}, 'genetic': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715}, 'pgd': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715}, 'homoglyph': {'precision': 1.0, 'recall': 0.25, 'f1': 0.4}}), ('Caroline’s patient ID is 987654, and she must present it during the check-in process.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'genetic': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'pgd': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('The cardiologist requested that Mr. Delaney return on 10/31/2025 for a stress test.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.6666666666666666, 'recall': 1.0, 'f1': 0.8}}), ('The nurse reminded Joshua to call 555-111-2222 if he experiences any chest pain.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 0.8571428571428571, 'f1': 0.923076923076923}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2}}), ('Mrs. Ramirez has an appointment scheduled at 3:15 PM on February 20th with Dr. Vaughn.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}), ('Please send Tyler’s updated x-ray scans to t.henderson@medcenter.edu.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Ms. Nguyen’s biopsy results will be discussed during her phone consultation at 555-654-3210.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.25, 'recall': 0.5, 'f1': 0.3333333333333333}}), ('Dr. Cole instructed Harriet to rest for two weeks following her surgery on 08/25/2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}}), ('The dental office informed Mr. James that his cleaning was moved to May 6th at 10:00 AM.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575}}), ('Lisa’s recovery plan was emailed to her personal address, lisa.phelps@example.com, by Dr. Fisher.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}), ('Nurse Torres asked Jonathan to arrive at 8:30 AM on 09/09/2025 for routine bloodwork.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.6666666666666666, 'recall': 1.0, 'f1': 0.8}}), ('Dr. Sanders asked Maria to schedule her surgery on March 12, 2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('The clinic informed Michael at 555-987-6543 about his blood test results.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4}}), ('Nurse Alexis emailed the patient’s treatment plan to james.clark@hospital.org.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}, 'genetic': {'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}, 'pgd': {'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Taylor was advised to visit Room 204 at 9:00 AM on 06/15/2024 for a follow-up.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}, 'homoglyph': {'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4}}), ('Dr. Liu needs to review Lucas’s MRI scan results on April 8th.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333}, 'genetic': {'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333}, 'pgd': {'precision': 1.0, 'recall': 0.6666666666666666, 'f1': 0.8}, 'homoglyph': {'precision': 0.5, 'recall': 0.5, 'f1': 0.5}}), ('Ms. Jenkins left a voicemail at 555-222-3333 confirming her next appointment.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4}}), ('The hospital asked Christopher to update his insurance details by 07/01/2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 0.5, 'f1': 0.6666666666666666}}), ('At 2:00 PM on January 4, 2025, Dr. Patel met with Ms. Peterson to discuss lab findings.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'f1': 0.6666666666666666}}), ('Please instruct Amanda to email her medical history to patient.records@healthclinic.com.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}), ('Dr. Gomez recommended that Peter come back for tests every week until July 30, 2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715}, 'genetic': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715}, 'pgd': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715}, 'homoglyph': {'precision': 0.2857142857142857, 'recall': 0.5, 'f1': 0.36363636363636365}}), ('Caroline’s patient ID is 987654, and she must present it during the check-in process.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'genetic': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'pgd': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('The cardiologist requested that Mr. Delaney return on 10/31/2025 for a stress test.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}), ('The nurse reminded Joshua to call 555-111-2222 if he experiences any chest pain.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 0.8571428571428571, 'f1': 0.923076923076923}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Mrs. Ramirez has an appointment scheduled at 3:15 PM on February 20th with Dr. Vaughn.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'f1': 0.6666666666666666}}), ('Please send Tyler’s updated x-ray scans to t.henderson@medcenter.edu.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}), ('Ms. Nguyen’s biopsy results will be discussed during her phone consultation at 555-654-3210.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4}}), ('Dr. Cole instructed Harriet to rest for two weeks following her surgery on 08/25/2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 0.6666666666666666, 'f1': 0.8}}), ('The dental office informed Mr. James that his cleaning was moved to May 6th at 10:00 AM.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Lisa’s recovery plan was emailed to her personal address, lisa.phelps@example.com, by Dr. Fisher.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}), ('Nurse Torres asked Jonathan to arrive at 8:30 AM on 09/09/2025 for routine bloodwork.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Dr. Sanders asked Maria to schedule her surgery on March 12, 2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'f1': 0.6666666666666666}}), ('The clinic informed Michael at 555-987-6543 about his blood test results.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Nurse Alexis emailed the patient’s treatment plan to james.clark@hospital.org.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Taylor was advised to visit Room 204 at 9:00 AM on 06/15/2024 for a follow-up.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}, 'genetic': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}, 'pgd': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}, 'homoglyph': {'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4}}), ('Dr. Liu needs to review Lucas’s MRI scan results on April 8th.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333}, 'genetic': {'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333}, 'pgd': {'precision': 1.0, 'recall': 0.6666666666666666, 'f1': 0.8}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Ms. Jenkins left a voicemail at 555-222-3333 confirming her next appointment.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}), ('The hospital asked Christopher to update his insurance details by 07/01/2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('At 2:00 PM on January 4, 2025, Dr. Patel met with Ms. Peterson to discuss lab findings.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1': 0.3333333333333333}}), ('Please instruct Amanda to email her medical history to patient.records@healthclinic.com.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.3333333333333333, 'recall': 1.0, 'f1': 0.5}}), ('Dr. Gomez recommended that Peter come back for tests every week until July 30, 2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715}, 'genetic': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715}, 'pgd': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Caroline’s patient ID is 987654, and she must present it during the check-in process.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'genetic': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'pgd': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('The cardiologist requested that Mr. Delaney return on 10/31/2025 for a stress test.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}), ('The nurse reminded Joshua to call 555-111-2222 if he experiences any chest pain.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 0.8571428571428571, 'f1': 0.923076923076923}, 'genetic': {'precision': 1.0, 'recall': 0.7142857142857143, 'f1': 0.8333333333333333}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.3333333333333333, 'recall': 0.14285714285714285, 'f1': 0.2}}), ('Mrs. Ramirez has an appointment scheduled at 3:15 PM on February 20th with Dr. Vaughn.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'f1': 0.6666666666666666}}), ('Please send Tyler’s updated x-ray scans to t.henderson@medcenter.edu.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Ms. Nguyen’s biopsy results will be discussed during her phone consultation at 555-654-3210.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}), ('Dr. Cole instructed Harriet to rest for two weeks following her surgery on 08/25/2025.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}}), ('The dental office informed Mr. James that his cleaning was moved to May 6th at 10:00 AM.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}}), ('Lisa’s recovery plan was emailed to her personal address, lisa.phelps@example.com, by Dr. Fisher.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}), ('Nurse Torres asked Jonathan to arrive at 8:30 AM on 09/09/2025 for routine bloodwork.', {'original': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}, 'greedy': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'genetic': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'pgd': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'homoglyph': {'precision': 0.5, 'recall': 0.5, 'f1': 0.5}})]\n"
     ]
    }
   ],
   "source": [
    "print(total_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attack_types = ['original', 'greedy', 'genetic', 'pgd', 'homoglyph']\n",
    "f1_scores = {attack: [] for attack in attack_types}\n",
    "\n",
    "for item in total_results:  # Using total_results directly\n",
    "    metrics = item[1]\n",
    "    for attack in attack_types:\n",
    "        f1_scores[attack].append(metrics[attack]['f1'])\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "means = {attack: np.mean(scores) for attack, scores in f1_scores.items()}\n",
    "stds = {attack: np.std(scores) for attack, scores in f1_scores.items()}\n",
    "\n",
    "# Prepare data for plotting\n",
    "attacks = list(means.keys())\n",
    "mean_values = list(means.values())\n",
    "std_values = list(stds.values())\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(attacks, mean_values, yerr=std_values, capsize=5)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Average F1 Scores by Attack Type with Standard Deviation', fontsize=14)\n",
    "plt.xlabel('Attack Type', fontsize=12)\n",
    "plt.ylabel('F1 Score', fontsize=12)\n",
    "plt.ylim(0, 1.1)  # F1 score range is 0-1\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.3f}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
